import numpy as np
import random
import logging
import warnings
from pathlib import Path
import gc
import pickle
from typing import Dict, List, Tuple, Optional, Any
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import rcParams

# ML Libraries
import lightgbm as lgb # Changed from sklearn.ensemble to lightgbm
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import shap

# --- Matplotlib and Logging Configuration ---
# Set matplotlib font to a professional-looking serif font
plt.rcParams['font.family'] = 'DejaVu Serif'
plt.rcParams['font.size'] = 14
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['xtick.labelsize'] = 14
plt.rcParams['ytick.labelsize'] = 14
plt.rcParams['legend.fontsize'] = 14
plt.rcParams['figure.titlesize'] = 20
plt.rcParams['axes.grid'] = True
plt.rcParams['grid.alpha'] = 0.3
plt.rcParams['axes.facecolor'] = '#f9f9f9'
plt.rcParams['figure.facecolor'] = 'white'

# Custom color palette for plots
COLORS = ['#0077B6', '#D9534F', '#5CB85C', '#F0AD4E', '#5BC0DE', '#428BCA',
          '#777777', '#F4A261', '#264653', '#E76F51']

# Suppress warnings for a cleaner output
warnings.filterwarnings('ignore')

# Setup logging to file and console with UTF-8 encoding
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('subsidence_model_lgbm_forecast.log', 'w', encoding='utf-8'), # Changed log file name
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class LGBMSubsidencePredictor: # Renamed class
    """
    A machine learning framework for single-step subsidence forecasting using a LightGBM model.
    - Trains, validates, and tests on separate, pre-defined NPZ data files.
    - Forecasts exactly one time step into the future.
    - Automatically finds the optimal number of past time steps for model input.
    - Generates professional visualizations for model performance and feature importance.
    """

    def __init__(self, train_data_path: str, val_data_path: str, test_data_path: str, random_state: int = 42):
        """
        Initialize the subsidence predictor.

        Args:
            train_data_path: Path to the training NPZ data file.
            val_data_path: Path to the validation NPZ data file.
            test_data_path: Path to the testing NPZ data file.
            random_state: Random state for reproducibility.
        """
        self.train_data_path = train_data_path
        self.val_data_path = val_data_path
        self.test_data_path = test_data_path
        self.random_state = random_state
        self.future_steps = 1  # Hardcoded to forecast one step forward

        # Set random seeds for reproducibility
        np.random.seed(random_state)
        random.seed(random_state)

        logger.info(f"Forecasting {self.future_steps} step(s) ahead.")

        # --- Feature Definitions ---
        self.feature_names = [
            'Root Moisture (inst)', 'Soil Moisture 0-10cm (inst)', 'Soil Moisture 10-40cm (inst)',
            'Soil Moisture 40-100cm (inst)', 'Soil Moisture 100-200cm (inst)',
            'Soil Temperature 0-10cm (inst)', 'Soil Temperature 10-40cm (inst)',
            'Soil Temperature 40-100cm (inst)', 'Soil Temperature 100-200cm (inst)',
            'Evaporation (tavg)', 'Rainfall (tavg)', 'Subsurface Runoff (acc)',
            'Air Temperature (f inst)', 'Wind Speed (f inst)', 'Average Displacement (mm)',
            'Bulk Density Mean (0-5cm)', 'Cation Exchange Capacity Mean (0-5cm)',
            'Coarse Fragments Volumetric Mean (0-5cm)', 'Clay Content Mean (0-5cm)',
            'pH in Water Mean (0-5cm)', 'Sand Content Mean (0-5cm)', 'Silt Content Mean (0-5cm)',
            'Soil Organic Carbon Mean (0-5cm)', 'Bulk Density Mean (15-30cm)',
            'Cation Exchange Capacity Mean (15-30cm)', 'Coarse Fragments Volumetric Mean (15-30cm)',
            'Clay Content Mean (15-30cm)', 'pH in Water Mean (15-30cm)', 'Sand Content Mean (15-30cm)',
            'Silt Content Mean (15-30cm)', 'Soil Organic Carbon Mean (15-30cm)',
            'Bulk Density Mean (60-100cm)', 'Cation Exchange Capacity Mean (60-100cm)',
            'Coarse Fragments Volumetric Mean (60-100cm)', 'Clay Content Mean (60-100cm)',
            'pH in Water Mean (60-100cm)', 'Sand Content Mean (60-100cm)',
            'Silt Content Mean (60-100cm)', 'Soil Organic Carbon Mean (60-100cm)',
            'Bulk Density Mean (100-200cm)', 'Cation Exchange Capacity Mean (100-200cm)',
            'Coarse Fragments Volumetric Mean (100-200cm)', 'Clay Content Mean (100-200cm)',
            'pH in Water Mean (100-200cm)', 'Sand Content Mean (100-200cm)',
            'Silt Content Mean (100-200cm)', 'Soil Organic Carbon Mean (100-200cm)'
        ]
        self.selected_feature_names = [
            'Sand Content Mean (15-30cm)', 'Silt Content Mean (60-100cm)',
            'Coarse Fragments Volumetric Mean (60-100cm)', 'Soil Organic Carbon Mean (15-30cm)',
            'Average Displacement (mm)', 'Root Moisture (inst)', 'Soil Temperature 10-40cm (inst)',
            'Evaporation (tavg)', 'Soil Moisture 0-10cm (inst)', 'Soil Moisture 10-40cm (inst)'
        ]
        self.target_name = 'Average Displacement (mm)'
        self.target_index = self.feature_names.index(self.target_name)

        # --- Model and Data Storage ---
        self.train_data, self.val_data, self.test_data = None, None, None
        self.model = None
        self.model_results = {}
        self.optimal_time_steps = 0
        self.feature_indices = []
        self.X_test_flat = None
        self.X_train_flat_sample = None
        self.flat_feature_names = None

        # Best hyperparameters for LightGBM (pre-defined)
        self.best_params = {
            'objective': 'regression_l1',  # MAE for robustness
            'metric': 'rmse',
            'n_estimators': 2000,          # High value, will be controlled by early stopping
            'learning_rate': 0.02,
            'feature_fraction': 0.8,
            'bagging_fraction': 0.8,
            'bagging_freq': 1,
            'lambda_l1': 0.1,
            'lambda_l2': 0.1,
            'num_leaves': 31,
            'verbose': -1,
            'n_jobs': -1,
            'seed': self.random_state,
            'boosting_type': 'gbdt',
        }

        # Create output directory for saving results
        self.output_dir = Path("lgbm_forecast_outputs") # Renamed directory
        self.output_dir.mkdir(exist_ok=True)

    def _load_data_from_path(self, path: str) -> np.ndarray:
        """Helper function to load data from a single NPZ file."""
        try:
            logger.info(f"Loading data from: {path}")
            npz_file = np.load(path)
            data = npz_file['data']
            if len(data.shape) != 3:
                raise ValueError(f"Expected 3D data in {path}, but got {len(data.shape)}D")
            logger.info(f"  - Data shape: {data.shape}")
            return data
        except Exception as e:
            logger.error(f"Error loading data from {path}: {str(e)}")
            raise

    def load_datasets(self) -> None:
        """Load the training, validation, and test datasets from their respective files."""
        self.train_data = self._load_data_from_path(self.train_data_path)
        self.val_data = self._load_data_from_path(self.val_data_path)
        self.test_data = self._load_data_from_path(self.test_data_path)

        self.feature_indices = [self.feature_names.index(name) for name in self.selected_feature_names]
        logger.info(f"Selected feature indices: {self.feature_indices}")

    def create_sequences(self, data: np.ndarray, past_months: int) -> Tuple[np.ndarray, np.ndarray]:
        """Create input sequences and corresponding targets from a given dataset."""
        sequences, targets = [], []
        num_timesteps, num_grid_cells, _ = data.shape

        for grid_idx in range(num_grid_cells):
            for t in range(past_months, num_timesteps - self.future_steps + 1):
                seq = data[t - past_months:t, grid_idx, self.feature_indices]
                target = data[t:t + self.future_steps, grid_idx, self.target_index]
                sequences.append(seq)
                targets.append(target)

        sequences, targets = np.array(sequences), np.array(targets)
        valid_mask = ~(np.isnan(sequences).any(axis=(1, 2)) | np.isnan(targets).any(axis=1))
        return sequences[valid_mask], targets[valid_mask]

    def find_optimal_time_steps(self) -> int:
        """Find the optimal number of past time steps by evaluating on the validation set."""
        logger.info("Finding optimal number of past time steps for input...")
        results = []
        time_steps_range = range(2, 13)

        for past_months in time_steps_range:
            try:
                X_train, y_train = self.create_sequences(self.train_data, past_months)
                X_val, y_val = self.create_sequences(self.val_data, past_months)

                if len(X_train) < 100 or len(X_val) < 20:
                    logger.warning(f"Skipping {past_months} time steps due to insufficient samples.")
                    continue

                X_train_flat = X_train.reshape(X_train.shape[0], -1)
                X_val_flat = X_val.reshape(X_val.shape[0], -1)

                # Use a simple, fast LGBM model for this evaluation
                model = lgb.LGBMRegressor(random_state=self.random_state, verbose=-1)
                model.fit(X_train_flat, y_train.ravel())
                val_score = r2_score(y_val, model.predict(X_val_flat))

                results.append({'past_months': past_months, 'val_r2': val_score})
                logger.info(f"  - Time steps: {past_months}, Validation R²: {val_score:.4f}")

            except Exception as e:
                logger.error(f"Error while testing {past_months} time steps: {str(e)}")
                continue

        if not results:
            raise ValueError("Could not find a valid time step configuration. Check data quality and size.")

        best_result = max(results, key=lambda x: x['val_r2'])
        optimal_steps = best_result['past_months']
        logger.info(f"Optimal time steps found: {optimal_steps} (Validation R²: {best_result['val_r2']:.4f})")
        return optimal_steps

    def train_lgbm_model(self) -> None: # Renamed method
        """Train and evaluate the final LightGBM model using optimal time steps and early stopping."""
        self.optimal_time_steps = self.find_optimal_time_steps()
        logger.info(f"\nTraining final LightGBM with {self.optimal_time_steps} optimal time steps...")

        self.flat_feature_names = [
            f'{f.split("(")[0].strip()} (t-{self.optimal_time_steps-t-1})' 
            for t in range(self.optimal_time_steps) 
            for f in self.selected_feature_names
        ]

        X_train, y_train = self.create_sequences(self.train_data, self.optimal_time_steps)
        X_val, y_val = self.create_sequences(self.val_data, self.optimal_time_steps)
        X_test, y_test = self.create_sequences(self.test_data, self.optimal_time_steps)

        X_train_flat = X_train.reshape(X_train.shape[0], -1)
        X_val_flat = X_val.reshape(X_val.shape[0], -1)
        self.X_test_flat = X_test.reshape(X_test.shape[0], -1)
        
        y_train_flat = y_train.ravel()
        y_val_flat = y_val.ravel()
        y_test_flat = y_test.ravel()

        self.X_train_flat_sample = shap.sample(X_train_flat, 100, random_state=self.random_state)
        
        self.model = lgb.LGBMRegressor(**self.best_params)
        logger.info(f"Using hyperparameters: {self.best_params}")
        logger.info("Training with early stopping...")

        self.model.fit(
            X_train_flat, 
            y_train_flat,
            eval_set=[(X_val_flat, y_val_flat)],
            eval_metric='rmse',
            callbacks=[lgb.early_stopping(100, verbose=True)] # Stop if validation RMSE does not improve for 100 rounds
        )
        
        logger.info(f"Model trained for {self.model.best_iteration_} iterations (early stopping).")

        y_train_pred = self.model.predict(X_train_flat)
        y_val_pred = self.model.predict(X_val_flat)
        y_test_pred = self.model.predict(self.X_test_flat)

        self.model_results = {
            'train': {'r2': r2_score(y_train_flat, y_train_pred), 'rmse': np.sqrt(mean_squared_error(y_train_flat, y_train_pred)), 'mae': mean_absolute_error(y_train_flat, y_train_pred)},
            'val': {'r2': r2_score(y_val_flat, y_val_pred), 'rmse': np.sqrt(mean_squared_error(y_val_flat, y_val_pred)), 'mae': mean_absolute_error(y_val_flat, y_val_pred)},
            'test': {'r2': r2_score(y_test_flat, y_test_pred), 'rmse': np.sqrt(mean_squared_error(y_test_flat, y_test_pred)), 'mae': mean_absolute_error(y_test_flat, y_test_pred)},
            'predictions': {'y_test_pred': y_test_pred, 'y_test': y_test_flat}
        }
        logger.info(f"LightGBM - Train R²: {self.model_results['train']['r2']:.4f}, Val R²: {self.model_results['val']['r2']:.4f}, Test R²: {self.model_results['test']['r2']:.4f}")

    def plot_performance_summary(self) -> None:
        """Plot the performance metrics (R², RMSE, MAE) for all data splits."""
        fig, axes = plt.subplots(1, 3, figsize=(20, 6))
        metrics = ['r2', 'rmse', 'mae']
        metric_names = ['R² Score', 'RMSE (mm)', 'MAE (mm)']
        
        for idx, (metric, name) in enumerate(zip(metrics, metric_names)):
            ax = axes[idx]
            values = [self.model_results[split][metric] for split in ['train', 'val', 'test']]
            bars = ax.bar(['Train', 'Validation', 'Test'], values, color=COLORS[:3], alpha=0.8)
            ax.set_title(f'LightGBM - {name}', fontsize=16, fontweight='bold')
            ax.set_ylabel(name, fontsize=14)
            ax.grid(True, alpha=0.3, axis='y')

            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height, f'{height:.3f}', ha='center', va='bottom', fontsize=12)

        plt.suptitle('LightGBM Performance Summary', fontsize=20, fontweight='bold')
        plt.tight_layout(rect=[0, 0, 1, 0.96])
        plt.savefig(self.output_dir / 'lgbm_performance_summary.png', dpi=400, bbox_inches='tight')
        plt.close()
        logger.info("  - Saved performance summary plot.")

    def plot_actual_vs_predicted(self) -> None:
        """Plot a scatter graph of actual vs. predicted values for the test set."""
        y_test = self.model_results['predictions']['y_test']
        y_test_pred = self.model_results['predictions']['y_test_pred']
        r2, rmse, mae = self.model_results['test']['r2'], self.model_results['test']['rmse'], self.model_results['test']['mae']

        plt.figure(figsize=(10, 8))
        plt.scatter(y_test, y_test_pred, alpha=0.5, color=COLORS[0], edgecolors='k', s=50)
        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2.5, label='Ideal Fit')
        plt.xlabel('Actual Displacement (mm)', fontsize=14)
        plt.ylabel('Predicted Displacement (mm)', fontsize=14)
        plt.title(f'Actual vs. Predicted Displacement (Test Set)\nR² = {r2:.4f}', fontsize=16, fontweight='bold')
        textstr = f'RMSE: {rmse:.3f} mm\nMAE: {mae:.3f} mm'
        plt.text(0.05, 0.95, textstr, transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        plt.grid(True, alpha=0.3)
        plt.legend()
        plt.savefig(self.output_dir / 'lgbm_actual_vs_predicted.png', dpi=400, bbox_inches='tight')
        plt.close()
        logger.info("  - Saved actual vs. predicted plot.")

    def plot_prediction_residuals(self) -> None:
        """Plot the residuals of the predictions on the test set."""
        residuals = self.model_results['predictions']['y_test'] - self.model_results['predictions']['y_test_pred']

        plt.figure(figsize=(12, 7))
        sns.histplot(residuals, kde=True, color=COLORS[4], bins=50)
        plt.title('Distribution of Prediction Residuals (Test Set)', fontsize=16, fontweight='bold')
        plt.xlabel('Residual (Actual - Predicted) (mm)', fontsize=14)
        plt.ylabel('Frequency', fontsize=14)
        plt.axvline(0, color='r', linestyle='--', lw=2)
        plt.grid(True, alpha=0.3)
        plt.savefig(self.output_dir / 'lgbm_prediction_residuals.png', dpi=400, bbox_inches='tight')
        plt.close()
        logger.info("  - Saved prediction residuals plot.")

    def plot_feature_importance(self) -> None:
        """Plot the most important features as determined by the trained model."""
        importances = self.model.feature_importances_
        feature_names = self.flat_feature_names 
        indices = np.argsort(importances)[::-1][:20]

        plt.figure(figsize=(12, 10))
        plt.title('Top 20 Feature Importances for LightGBM', fontsize=16, fontweight='bold')
        bars = plt.barh(range(len(indices)), importances[indices][::-1], color=COLORS[0], align='center')
        plt.yticks(range(len(indices)), [feature_names[i] for i in indices][::-1])
        plt.xlabel('Feature Importance (Split Count)', fontsize=14) # Changed label
        
        plt.grid(True, alpha=0.3, axis='x')
        plt.tight_layout()
        plt.savefig(self.output_dir / 'lgbm_feature_importance.png', dpi=400, bbox_inches='tight')
        plt.close()
        logger.info("  - Saved feature importance plot.")
        
    def plot_shap_feature_importance(self) -> None:
        """Calculates and plots SHAP feature importance."""
        logger.info("Calculating and plotting SHAP feature importance...")

        if self.model is None or self.X_test_flat is None or self.X_train_flat_sample is None:
            logger.warning("Model or data not available for SHAP analysis. Skipping.")
            return

        explainer = shap.TreeExplainer(self.model, self.X_train_flat_sample)
        shap_values = explainer.shap_values(self.X_test_flat)

        # SHAP Bar Plot
        plt.figure()
        shap.summary_plot(shap_values, self.X_test_flat, plot_type="bar", feature_names=self.flat_feature_names, show=False, color=COLORS[1], max_display=20)
        plt.title('SHAP Feature Importance (Mean Absolute SHAP Value)', fontsize=16, fontweight='bold')
        plt.xlabel("Mean |SHAP value| (Impact on model output)", fontsize=14)
        plt.tight_layout()
        plt.savefig(self.output_dir / 'lgbm_shap_bar_importance.png', dpi=400, bbox_inches='tight')
        plt.close()
        logger.info("  - Saved SHAP bar plot.")

        # SHAP Dot Plot
        plt.figure()
        shap.summary_plot(shap_values, self.X_test_flat, feature_names=self.flat_feature_names, show=False, max_display=20)
        plt.tight_layout()
        plt.savefig(self.output_dir / 'lgbm_shap_dot_summary.png', dpi=400, bbox_inches='tight')
        plt.close()
        logger.info("  - Saved SHAP dot summary plot.")

    def print_comprehensive_results(self) -> None:
        """Print a formatted, comprehensive summary of the final results to the console."""
        logger.info("\n" + "="*100)
        logger.info("LIGHTGBM SUBSIDENCE FORECASTING RESULTS") # Renamed
        logger.info("="*100)
        logger.info(f"Training Data:   {self.train_data_path}")
        logger.info(f"Validation Data: {self.val_data_path}")
        logger.info(f"Test Data:       {self.test_data_path}")
        logger.info(f"Time steps forecasted: {self.future_steps}")
        logger.info(f"Optimal past time steps used for input: {self.optimal_time_steps}")
        logger.info(f"Model trained for {self.model.best_iteration_} iterations (early stopped).")
        logger.info(f"Model Hyperparameters: {self.best_params}")
        logger.info("="*100)

        metrics = self.model_results
        logger.info("\nMODEL PERFORMANCE SUMMARY:")
        logger.info("-" * 50)
        logger.info(f"{'Split':<12}{'R² Score':<12}{'RMSE (mm)':<12}{'MAE (mm)':<12}")
        logger.info("-" * 50)
        logger.info(f"{'Training':<12}{metrics['train']['r2']:<12.4f}{metrics['train']['rmse']:<12.4f}{metrics['train']['mae']:<12.4f}")
        logger.info(f"{'Validation':<12}{metrics['val']['r2']:<12.4f}{metrics['val']['rmse']:<12.4f}{metrics['val']['mae']:<12.4f}")
        logger.info(f"{'Test':<12}{metrics['test']['r2']:<12.4f}{metrics['test']['rmse']:<12.4f}{metrics['test']['mae']:<12.4f}")
        logger.info("="*100)

    def save_model_and_results(self) -> None:
        """Save the trained model and a dictionary of results to disk using pickle."""
        with open(self.output_dir / 'lgbm_model.pickle', 'wb') as f:
            pickle.dump(self.model, f)
            
        results_to_save = {
            'model_results': self.model_results,
            'optimal_time_steps': self.optimal_time_steps,
            'best_hyperparameters': self.best_params,
            'selected_features': self.selected_feature_names,
            'future_steps_forecasted': self.future_steps,
            'best_iteration': self.model.best_iteration_
        }
        with open(self.output_dir / 'lgbm_results.pickle', 'wb') as f:
            pickle.dump(results_to_save, f)
            
        logger.info(f"Model and results dictionary saved to '{self.output_dir}/'")

    def run_complete_pipeline(self) -> None:
        """Execute the complete machine learning pipeline from data loading to saving results."""
        logger.info("Starting LightGBM Subsidence Forecasting Pipeline...")
        try:
            self.load_datasets()
            self.train_lgbm_model() # Renamed method call
            
            logger.info("\nCreating and saving visualizations...")
            self.plot_performance_summary()
            self.plot_actual_vs_predicted()
            self.plot_prediction_residuals()
            self.plot_feature_importance()
            self.plot_shap_feature_importance()

            self.print_comprehensive_results()
            self.save_model_and_results()

            logger.info("\nPipeline completed successfully!")
            logger.info(f"All outputs have been saved to: {self.output_dir.absolute()}")

        except Exception as e:
            logger.error(f"The pipeline failed with an error: {str(e)}", exc_info=True)
            raise

# --- Main Execution Block ---
if __name__ == "__main__":
    TRAIN_DATA_PATH = "/content/URM_TEH_NEY_MARV_LENJ.npz"
    VAL_DATA_PATH = "/content/BARD.npz"
    TEST_DATA_PATH = "/content/SEMN_DOLAT.npz"
    RANDOM_STATE = 42

    # Instantiate the new predictor class
    predictor = LGBMSubsidencePredictor(
        train_data_path=TRAIN_DATA_PATH,
        val_data_path=VAL_DATA_PATH,
        test_data_path=TEST_DATA_PATH,
        random_state=RANDOM_STATE
    )
    
    predictor.run_complete_pipeline()